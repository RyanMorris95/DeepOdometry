{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrecord = \"/media/ryan/UBUNTU 16_0/train_sfm.tfrecord\"\n",
    "all_poses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parser(record):\n",
    "    keys_to_features = {\n",
    "        \"pose\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        \"img_raw\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        \"img_raw_prev\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "    }\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    # Perform additional preprocessing on the parsed data.\n",
    "    image = tf.image.decode_jpeg(parsed[\"img_raw\"])\n",
    "    image = tf.reshape(image, [128, 416, 1])\n",
    "    image_prev = tf.image.decode_jpeg(parsed[\"img_raw_prev\"])\n",
    "    image_prev = tf.reshape(image_prev, [128, 416, 1])\n",
    "    \n",
    "    label = tf.decode_raw(parsed[\"pose\"], tf.float64)\n",
    "    label = tf.reshape(label, [12])\n",
    "\n",
    "    return image, image_prev, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(parser)\n",
    "dataset = dataset.batch(32)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "all_poses = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize 'iterator' with training data\n",
    "    training_filenames = ['/media/ryan/UBUNTU 16_0/train_sfm.tfrecord']\n",
    "    sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "    for i in range(int(18500/32)):\n",
    "        images, images_prev, labels = iterator.get_next()\n",
    "        images, images_prev, labels = sess.run([images, images_prev, labels])\n",
    "        labels = labels.tolist()\n",
    "        all_poses += labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(all_poses))\n",
    "all_poses_arr = np.array(all_poses)\n",
    "print (all_poses_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(all_poses_arr)\n",
    "std = np.std(all_poses_arr)\n",
    "print (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_poses_scaled = all_poses_arr\n",
    "all_poses_scaled -= mean\n",
    "all_poses_scaled /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (all_poses_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(all_poses_arr)\n",
    "all_poses_scikit = scaler.transform(all_poses_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (all_poses_scikit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (scaler.mean_)\n",
    "print (scaler.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(all_poses_scikit[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "print (np.array(data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as p\n",
    "\n",
    "with open('pose_scaler.p', 'wb') as fp:\n",
    "    p.dump(scaler, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(parser)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.shuffle(buffer_size=500)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "all_images = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize 'iterator' with training data\n",
    "    training_filenames = ['/media/ryan/UBUNTU 16_0/train_sfm.tfrecord']\n",
    "    sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "    for i in range(int(5000)):\n",
    "        if i %500 == 0:\n",
    "            print (i)\n",
    "        images, images_prev, labels = iterator.get_next()\n",
    "        images, images_prev, labels = sess.run([images, images_prev, labels])\n",
    "        all_images.append(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_arr = np.array(all_images).astype('float')\n",
    "print (all_images_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_arr = all_images_arr.squeeze()\n",
    "print (all_images_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = np.mean(all_images_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(all_images_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_arr -= mean\n",
    "all_images_arr /= std\n",
    "print (all_images_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
