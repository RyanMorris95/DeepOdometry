{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib import slim\n",
    "from tensorflow.contrib.learn import ModeKeys\n",
    "from tensorflow.contrib.learn import learn_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 18500\n",
    "EVAL_SIZE = 2500\n",
    "MEAN = 127\n",
    "STD = 127\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN STEPS:  555000\n",
      "EVAL STEPS:  1250\n",
      "EPOCH STEPS:  9250\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "batch_size = 2\n",
    "epochs = 60\n",
    "TRAIN_STEPS = int(TRAIN_SIZE/batch_size)*epochs\n",
    "EVAL_STEPS = int(EVAL_SIZE/batch_size)\n",
    "EPOCH_STEPS = int(TRAIN_SIZE/batch_size)\n",
    "print (\"TRAIN STEPS: \", TRAIN_STEPS)\n",
    "print (\"EVAL STEPS: \", EVAL_STEPS)\n",
    "print (\"EPOCH STEPS: \", EPOCH_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def architecture(inputs, is_training, scope='MnistConvNet'):\n",
    "    \"\"\"Return the output operation following the network architecture.\n",
    "    Args:\n",
    "        inputs (Tensor): Input Tensor\n",
    "        is_training (bool): True iff in training mode\n",
    "        scope (str): Name of the scope of the architecture\n",
    "    Returns:\n",
    "         Logits output Op for the network.\n",
    "    \"\"\"\n",
    "    print (inputs)\n",
    "    with tf.variable_scope(scope):\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(inputs, 32, 5, activation=tf.nn.relu)\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 4, 2)\n",
    "\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 4, 2)\n",
    "\n",
    "        conv3 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        conv3 = tf.layers.max_pooling2d(conv3, 4, 2)\n",
    "        \n",
    "        fc1 = tf.layers.flatten(conv3)\n",
    "\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=0.5, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, 12)\n",
    "\n",
    "        return out\n",
    "    \n",
    "def nvidia_architecture(inputs, is_training, scope='Nvidia'):\n",
    "    with tf.variable_scope(scope):\n",
    "        net = tf.layers.conv2d(inputs, 24, 5, strides=(2, 2), activation=tf.nn.relu, name='conv1')\n",
    "        net = tf.layers.conv2d(net, 36, 5, strides=(2, 2), activation=tf.nn.relu, name='conv2')\n",
    "        net = tf.layers.conv2d(net, 48, 5, strides=(2, 2), activation=tf.nn.relu, name='conv3')\n",
    "        net = tf.layers.conv2d(net, 64, 3, activation=tf.nn.relu, name='conv4')\n",
    "        net = tf.layers.conv2d(net, 64, 3, activation=tf.nn.relu, name='conv5')\n",
    "        \n",
    "        net = tf.layers.flatten(net)\n",
    "        net = tf.layers.dense(net, 1164, activation=tf.nn.relu, name='fc1')\n",
    "        net = tf.layers.dropout(net, rate=0.7, training=is_training)\n",
    "        \n",
    "        net = tf.layers.dense(net, 100, activation=tf.nn.relu, name='fc2')\n",
    "        net = tf.layers.dropout(net, rate=0.7, training=is_training)\n",
    "        \n",
    "        net = tf.layers.dense(net, 50, activation=tf.nn.relu, name='fc3')\n",
    "        net = tf.layers.dropout(net, rate=0.7, training=is_training)\n",
    "        \n",
    "        net = tf.layers.dense(net, 20, activation=tf.nn.relu, name='fc4')\n",
    "        \n",
    "        # scaling based on sfmlearner\n",
    "        predictions = 0.01 * tf.layers.dense(net, 12, activation=None, name='predictions')\n",
    "        return predictions\n",
    "    \n",
    "def sfmlearner_architecture(inputs, is_training, scope='sfmlearner'):\n",
    "    with tf.variable_scope(scope):\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=0.05)\n",
    "        net = tf.layers.conv2d(inputs, 16, 7, strides=(2, 2), activation=tf.nn.relu, name='conv1', kernel_regularizer=regularizer)\n",
    "        net = tf.layers.conv2d(net, 32, 5, strides=(2, 2), activation=tf.nn.relu, name='conv2', kernel_regularizer=regularizer)\n",
    "        net = tf.layers.conv2d(net, 64, 3, strides=(2, 2), activation=tf.nn.relu, name='conv3', kernel_regularizer=regularizer)\n",
    "        net = tf.layers.conv2d(net, 128, 3, strides=(2, 2), activation=tf.nn.relu, name='conv4', kernel_regularizer=regularizer)\n",
    "        net = tf.layers.conv2d(net, 256, 3, strides=(2, 2), activation=tf.nn.relu, name='conv5', kernel_regularizer=regularizer)\n",
    "        net = tf.layers.conv2d(net, 256, 3, strides=(2, 2), activation=tf.nn.relu, name='conv6', kernel_regularizer=regularizer)\n",
    "        net = tf.layers.conv2d(net, 256, 3, strides=(2, 2), activation=tf.nn.relu, name='conv7', kernel_regularizer=regularizer)\n",
    "        predictions = tf.layers.dense(net, 12, activation=None, name='predictions')\n",
    "        predictions = tf.reduce_mean(predictions, [1, 2])\n",
    "        predictions = 0.01 * tf.reshape(predictions, [-1, ])\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "def sfmlearner_architecture2(inputs, is_training, scope='sfmlearner'):\n",
    "    slim = tf.contrib.slim\n",
    "    with tf.variable_scope('pose_exp_net') as sc:\n",
    "        with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n",
    "                            normalizer_fn=None,\n",
    "                            weights_regularizer=slim.l2_regularizer(0.05),\n",
    "                            activation_fn=tf.nn.relu):\n",
    "            # cnv1 to cnv5b are shared between pose and explainability prediction\n",
    "            cnv1  = slim.conv2d(inputs,16,  [7, 7], stride=2, scope='cnv1')\n",
    "            cnv2  = slim.conv2d(cnv1, 32,  [5, 5], stride=2, scope='cnv2')\n",
    "            cnv3  = slim.conv2d(cnv2, 64,  [3, 3], stride=2, scope='cnv3')\n",
    "            cnv4  = slim.conv2d(cnv3, 128, [3, 3], stride=2, scope='cnv4')\n",
    "            cnv5  = slim.conv2d(cnv4, 256, [3, 3], stride=2, scope='cnv5')\n",
    "            # Pose specific layers\n",
    "            with tf.variable_scope('pose'):\n",
    "                cnv6  = slim.conv2d(cnv5, 256, [3, 3], stride=2, scope='cnv6')\n",
    "                cnv7  = slim.conv2d(cnv6, 256, [3, 3], stride=2, scope='cnv7')\n",
    "                pose_pred = slim.conv2d(cnv7, 6, [1, 1], scope='pred', \n",
    "                    stride=1, normalizer_fn=None, activation_fn=None)\n",
    "                pose_avg = tf.reduce_mean(pose_pred, [1, 2])\n",
    "                # Empirically we found that scaling by a small constant \n",
    "                # facilitates training.\n",
    "                pose_final = tf.reshape(pose_avg, [-1, 6])\n",
    "    return pose_final\n",
    "\n",
    "def deepvo_architecture(inputs, is_training, scope='deepvo'):\n",
    "    slim = tf.contrib.slim\n",
    "    with tf.variable_scope('deepvo') as sc:\n",
    "        with slim.arg_scope([slim.conv2d],\n",
    "                           activation_fn=tf.nn.relu):\n",
    "            cnv1 = slim.conv2d(inputs, 64, [7, 7], stride=2)\n",
    "            cnv2 = slim.conv2d(cnv1, 128, [5, 5], stride=2)\n",
    "            cnv3 = slim.conv2d(cnv2, 256, [5, 5], stride=2)\n",
    "            cnv3_1 = slim.conv2d(cnv3, 256, [3, 3])\n",
    "            cnv4 = slim.conv2d(cnv3_1, 512, [3, 3], stride=2)\n",
    "            cnv4_1 = slim.conv2d(cnv4, 512, [3, 3])\n",
    "            cnv5 = slim.conv2d(cnv4_1, 512, [3, 3], stride=2)\n",
    "            cnv5_1 = slim.conv2d(cnv5, 512, [3, 3])\n",
    "            cnv6 = slim.conv2d(cnv5_1, 1024, [3, 3], stride=2)\n",
    "            pose_pred = slim.conv2d(cnv6, 6, [1, 1], scope='pred', normalizer_fn=None,\n",
    "                                   activation_fn=None)\n",
    "            pose_avg = tf.reduce_mean(pose_pred, [1, 2])\n",
    "            pose_final = tf.reshape(pose_avg, [-1, 6])\n",
    "    return pose_final\n",
    "    \n",
    "def get_train_op_fn(loss, params, lr):\n",
    "    return tf.contrib.layers.optimize_loss(loss=loss, global_step=tf.contrib.framework.get_global_step(),\n",
    "                                          optimizer=tf.train.AdamOptimizer, learning_rate=lr)\n",
    "    \n",
    "def model_fn(features, labels, mode, params):\n",
    "    is_training = mode == ModeKeys.TRAIN\n",
    "    \n",
    "    #predictions = nvidia_architecture(features, is_training=is_training)\n",
    "    predictions = sfmlearner_architecture2(features, is_training=is_training)\n",
    "    #predictions = deepvo_architecture(features, is_training=is_training)\n",
    "    \n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = {}\n",
    "    #if mode != ModeKeys.INFER:\n",
    "        #loss = tf.reduce_mean(tf.losses.absolute_difference(labels, predictions), name='loss')\n",
    "        #loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions, scope='loss')\n",
    "        #train_op = get_train_op_fn(loss, params)\n",
    "        \n",
    "    # deepvo loss\n",
    "    if mode != ModeKeys.INFER:\n",
    "        print (predictions, labels)\n",
    "        trans_pred, rot_pred = tf.split(predictions, 2, axis=1)  \n",
    "        trans_label, rot_label = tf.split(labels, 2, axis=1)  \n",
    "\n",
    "        rot_loss = tf.losses.mean_squared_error(rot_label, rot_pred, scope='rot_loss')\n",
    "        trans_loss = tf.losses.mean_squared_error(trans_label, trans_pred, scope='trans_loss')\n",
    "        loss = tf.add(rot_loss, trans_loss)\n",
    "        \n",
    "        global_step = tf.train.get_global_step()\n",
    "        lr = tf.train.exponential_decay(LR, global_step, int(TRAIN_STEPS/5), 0.5, staircase=True, name='lr')    \n",
    "        train_op = get_train_op_fn(loss, params, lr)\n",
    "        \n",
    "#     image_curr, image_prev = tf.split(features, 2, axis=3)\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('rot_loss', rot_loss)\n",
    "    tf.summary.scalar('trans_loss', trans_loss)\n",
    "    tf.summary.scalar('lr', lr)\n",
    "\n",
    "    \n",
    "    for var in tf.trainable_variables():\n",
    "        tf.summary.histogram(var.name, var)\n",
    "#     tf.summary.image('prev_images', image_prev)\n",
    "#     tf.summary.image('curr_images', image_curr)\n",
    "#     tf.summary.image('diff_images', tf.abs(tf.subtract(image_prev, image_curr)))\n",
    "        \n",
    "    tensors_to_log = {'loss': loss, 'rot_loss': rot_loss, 'trans_loss': trans_loss}\n",
    "    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=500)\n",
    "    train_hooks = [logging_hook]\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op, training_hooks=train_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 128\n",
    "WIDTH = 416\n",
    "DEPTH = 3\n",
    "\n",
    "class KittiDataset(object):\n",
    "    def __init__(self, data_dir, subset='train', use_distortion=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.subset = subset\n",
    "        self.use_distortion = use_distortion\n",
    "        \n",
    "    def get_filenames(self):\n",
    "        if self.subset in ['train', 'validation', 'eval']:\n",
    "            return [os.path.join(self.data_dir, self.subset + '_eul_color_scale_tiny.tfrecord')]\n",
    "            #return [os.path.join(self.data_dir, 'train/train00.odometry')]\n",
    "        else:\n",
    "            raise ValueError('Invalid data subset \"%s\"' % self.subset)\n",
    "            \n",
    "    def parser(self, record):\n",
    "        keys_to_features = {\n",
    "            \"pose\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "            \"img_raw\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "            \"img_raw_prev\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        }\n",
    "        parsed = tf.parse_single_example(record, keys_to_features)\n",
    "\n",
    "        # Perform additional preprocessing on the parsed data.\n",
    "        image = tf.image.decode_jpeg(parsed[\"img_raw\"])\n",
    "        image = tf.reshape(image, [HEIGHT, WIDTH, DEPTH])\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        \n",
    "        image_prev = tf.image.decode_jpeg(parsed[\"img_raw_prev\"])\n",
    "        image_prev = tf.reshape(image_prev, [HEIGHT, WIDTH, DEPTH])\n",
    "        image_prev = tf.cast(image_prev, tf.float32)\n",
    "        \n",
    "        label = tf.decode_raw(parsed[\"pose\"], tf.float64)\n",
    "        label = tf.reshape(label, [6])\n",
    "        \n",
    "        return image, image_prev, label\n",
    "    \n",
    "    def make_batch(self, batch_size):\n",
    "        filenames = self.get_filenames()\n",
    "        \n",
    "        dataset = tf.data.TFRecordDataset(filenames).repeat()\n",
    "        \n",
    "        # parse records\n",
    "        dataset = dataset.map(self.parser, num_parallel_calls=8)\n",
    "        dataset = dataset.shuffle(buffer_size=5)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        image_batch, image_prev_batch, label_batch = iterator.get_next()\n",
    "        \n",
    "        image_batch = self.preprocess(image_batch, image_prev_batch)\n",
    "        \n",
    "        return image_batch, label_batch\n",
    "    \n",
    "    def _image_augmentation(self, image, seed=42):\n",
    "        image = tf.image.resize_images(image, tf.constant([int(HEIGHT/2), int(WIDTH/2)], dtype=tf.int32))\n",
    "#         image = tf.image.random_brightness(image, 0.1, seed=seed)\n",
    "#         image = tf.image.random_contrast(image, lower=0.9, upper=1.1, seed=seed)\n",
    "        return image\n",
    "    \n",
    "    def preprocess(self, image, image_prev):\n",
    "        image = self._image_augmentation(image, seed=42)\n",
    "        image_prev = self._image_augmentation(image_prev, seed=42)\n",
    "        \n",
    "        image = tf.divide(image, 255.)\n",
    "        image_prev = tf.divide(image, 255.)\n",
    "\n",
    "        image = tf.concat([image, image_prev], axis=3)\n",
    "        #image = tf.image.resize_image_with_crop_or_pad(image, 25, 100)\n",
    "        return image\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(data_dir, subset, batch_size, use_distortion_for_training=True):\n",
    "    with tf.device('/cpu:0'):\n",
    "        use_distortion = subset == 'train' and use_distortion_for_training\n",
    "        dataset = KittiDataset(data_dir, subset, use_distortion)\n",
    "        image_batch, label_batch = dataset.make_batch(batch_size)\n",
    "        return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_experiment_fn(data_dir, use_distortion_for_training=True):\n",
    "    def _experiment_fn(run_config, hparams):\n",
    "        train_input_fn = functools.partial(input_fn, data_dir, subset='train', batch_size=batch_size, use_distortion_for_training=True)\n",
    "        eval_input_fn = functools.partial(input_fn, data_dir, subset='eval', batch_size=batch_size)\n",
    "        \n",
    "        train_steps = 1000\n",
    "        eval_steps = EVAL_STEPS\n",
    "        \n",
    "        classifier = tf.estimator.Estimator(model_fn=model_fn, config=run_config, params=hparams)\n",
    "        \n",
    "        return tf.contrib.learn.Experiment(classifier, train_input_fn=train_input_fn,\n",
    "                                          eval_input_fn=eval_input_fn, train_steps=train_steps,\n",
    "                                          eval_steps=eval_steps)\n",
    "    return _experiment_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(data_dir, use_distortion_for_training):\n",
    "    \"\"\"Run the training experiment.\"\"\"\n",
    "    # Define model parameters\n",
    "    params = tf.contrib.training.HParams(\n",
    "        learning_rate=LR,\n",
    "        n_classes=6,\n",
    "        train_steps=1000,\n",
    "        min_eval_frequency=0\n",
    "    )\n",
    "\n",
    "    # Set the run_config and the directory to save the model and stats\n",
    "    run_config = tf.contrib.learn.RunConfig()\n",
    "    run_config = run_config.replace(model_dir='./kitti_training_eulcolor_tiny')\n",
    "\n",
    "    \n",
    "    learn_runner.run(\n",
    "        experiment_fn=get_experiment_fn(data_dir, use_distortion_for_training),  # First-class function\n",
    "        run_config=run_config,  # RunConfig\n",
    "        schedule=\"train\",  # What to run\n",
    "        hparams=params  # HParams\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff027b21208>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './kitti_training_eulcolor_tiny'}\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "Tensor(\"pose_exp_net/pose/Reshape:0\", shape=(?, 6), dtype=float32) Tensor(\"IteratorGetNext:2\", shape=(?, 6), dtype=float64, device=/device:CPU:0)\n",
      "WARNING:tensorflow:From <ipython-input-4-d1c64e185acb>:118: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Summary name pose_exp_net/cnv1/weights:0 is illegal; using pose_exp_net/cnv1/weights_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/cnv1/biases:0 is illegal; using pose_exp_net/cnv1/biases_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/cnv2/weights:0 is illegal; using pose_exp_net/cnv2/weights_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/cnv2/biases:0 is illegal; using pose_exp_net/cnv2/biases_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/cnv3/weights:0 is illegal; using pose_exp_net/cnv3/weights_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/cnv3/biases:0 is illegal; using pose_exp_net/cnv3/biases_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/cnv4/weights:0 is illegal; using pose_exp_net/cnv4/weights_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/cnv4/biases:0 is illegal; using pose_exp_net/cnv4/biases_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/cnv5/weights:0 is illegal; using pose_exp_net/cnv5/weights_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/cnv5/biases:0 is illegal; using pose_exp_net/cnv5/biases_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/pose/cnv6/weights:0 is illegal; using pose_exp_net/pose/cnv6/weights_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/pose/cnv6/biases:0 is illegal; using pose_exp_net/pose/cnv6/biases_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/pose/cnv7/weights:0 is illegal; using pose_exp_net/pose/cnv7/weights_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/pose/cnv7/biases:0 is illegal; using pose_exp_net/pose/cnv7/biases_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/pose/pred/weights:0 is illegal; using pose_exp_net/pose/pred/weights_0 instead.\n",
      "INFO:tensorflow:Summary name pose_exp_net/pose/pred/biases:0 is illegal; using pose_exp_net/pose/pred/biases_0 instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./kitti_training_eulcolor_tiny/model.ckpt.\n",
      "INFO:tensorflow:loss = 1408.16, step = 1\n",
      "INFO:tensorflow:loss = 1408.16, rot_loss = 1405.12, trans_loss = 3.03642\n",
      "INFO:tensorflow:global_step/sec: 30.9442\n",
      "INFO:tensorflow:loss = 13.3295, step = 101 (3.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.0899\n",
      "INFO:tensorflow:loss = 1.87814, step = 201 (1.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.9167\n",
      "INFO:tensorflow:loss = 0.682197, step = 301 (1.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.7041\n",
      "INFO:tensorflow:loss = 0.265615, step = 401 (1.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.5053\n",
      "INFO:tensorflow:loss = 1.00999, step = 501 (2.410 sec)\n",
      "INFO:tensorflow:loss = 1.00999, rot_loss = 0.672526, trans_loss = 0.33746 (10.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.6898\n",
      "INFO:tensorflow:loss = 0.327726, step = 601 (2.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8138\n",
      "INFO:tensorflow:loss = 6.19798, step = 701 (2.027 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-afce16112239>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'/home/ryan/DeepOdometry/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-9bb15b2f6bed>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(data_dir, use_distortion_for_training)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mrun_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# RunConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# What to run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m  \u001b[0;31m# HParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(experiment_fn, output_dir, schedule, run_config, hparams)\u001b[0m\n\u001b[1;32m    216\u001b[0m   \u001b[0mschedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_default_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_execute_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\u001b[0m in \u001b[0;36m_execute_schedule\u001b[0;34m(experiment, schedule)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Allowed values for this experiment are: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Schedule references non-callable member %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, delay_secs)\u001b[0m\n\u001b[1;32m    365\u001b[0m     return self._call_train(input_fn=self._train_input_fn,\n\u001b[1;32m    366\u001b[0m                             \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                             hooks=self._train_monitors + extra_hooks)\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36m_call_train\u001b[0;34m(self, _sentinel, input_fn, steps, hooks, max_steps)\u001b[0m\n\u001b[1;32m    805\u001b[0m                                    \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                                    \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                                    hooks=hooks)\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       return self._estimator.fit(input_fn=input_fn,\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    893\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.app.run(main=run_experiment( '/home/ryan/DeepOdometry/', False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
